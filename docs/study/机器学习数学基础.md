

date: 2013-12-05

category: 机器学习

tag:

  - 数学



机器学习数学

```perl
log 以10为底的对数记做lgN或者log
log 以e为底的对数记做lnN
p(x)lgN 数值越大,信息越紊乱,不确定
loga(MN)=logaN+logaM
loga(MM/N=logaN-logaM
无论log以10为底,log以2为底,log以e为底,对结果没有任何影响,不用纠结
为了统一,后面我们默认使用log以10 为底,并记作lg或者log
KL散度:就是两个概率分布间差异非对称性度量
通俗说,就是用来衡量同一个随机变量的两个不同分布之间的距离

交叉熵:主要是测量随机变量x的预测分布Q与真实分布P之间的差距

结论:预测越准确,交叉熵越小
结论:交叉熵只跟真实的标签有关
```

 ![image-20240110133639680](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240110133639680.png)

 ![image-20240110173648732](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240110173648732.png)

 ![image-20240119111804024](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240119111804024.png)

### 一 矩阵

1. 矩阵的基本知识

   ```perl
   A=[a11 a12 a13
      a21 a22 a23           ]
      
   B=[b11 b12 b13
      b21 b22 b23
     ]   
     
     A*BT(A 乘以B的转置)
   ```

   

2. 矩阵加法

   ```perl
   1)同型矩阵
   行数和列数相同的两个矩阵,称为同型矩阵,只有同型矩阵,才能做加减法.
   2)负矩阵
   两个矩阵的元素互为相反数
   3)矩阵的加法
   两个矩阵的对应元素分别相加
   4)矩阵加法减法,满足交换率和结合率
   5)矩阵的数乘,用这个数分别乘以矩阵的每个元素
   6)矩阵的乘法
   两个矩阵相乘满足的条件:
   第一个矩阵的列数,和第二个矩阵的行数相等
   行的元素和列的元素依次相乘并求和
   记忆:
   第一个矩阵的第一行 和第二矩阵的第一列元素,分布相差,并相加
   第一个矩阵的第一行和第二矩阵的第一列元素,分布相差,并相加
   第一个矩阵的第二行和第二个矩阵的第一列元素分布相差,并相加
   
   矩阵的乘法,不满足交换律,满足结合率和分配率
   因为:矩阵相乘,必须满足第一个矩阵的列数等于第二个矩阵的行数
   
   
   ```

   

3. 向量

   ```perl
   只有一行的矩阵,称为行向量
   a=[a1 a2 a3,a4]
   只有一列的矩阵,称为列向量
   
   向量的加减法和矩阵一样
   矩阵和向量相差,还是一个向量.
   
   ```

   

4. 概率论与统计

   1. 随机事件
   
      ```perl
   
      1)样本空间
      随机实验E所有可能结果构成的集合称为样本空间
      {正,反} {1,2,3,4,5,6}
      2)样本点
      样本空间的每一个元素称为样本点 e
      3)随机事件
      样本空间的子集称为随机事件
      A={1,3,5} 投掷骨子,出现奇数点
      
      4)事件A发生
      当事件A中某个样本点出现,称为事件发生.
      
      5)必然事件,就是样本空间自己
      6)不可能事件,就是空集
      ```
   
      
   
   2. 事件之间的关系(可以用维恩图表示)
   
      ```perl
      1)事件的包含
      A⊂B :若A事件发生,则必导致B事件发生
      2)事件的和
      A∪B 或者A+B  
      A发生 或者B发生
      A与B至少发生一个
      3)事件的积
      AB或者A∩B
      事件A发生,而且B发生
      事件A,B同时发生
      注意:ABC 含义,ABC均发生.
      4)事件的差
      A-B,事件A发生,单B不发生
      注意: A-B-C 事件A发生,B,C均不发生
      重要公式:
      A-B=A-AB
      5) 互不相容的事件(互斥事件)
      A与B互斥, AB=∮(空集)
      6)对立事件(互逆事件)
      AB=∮ AUB=Ω(全集) 
      —
      A  =B
      
      主要公式
                 —
      A-B=A-AB=A*B
      
      7)事件运算满足的定律
      1.交换率
      A∪B=B∪A
      2.结合率
      (A∪B)∪C=A∪(B∪C)
      3.分配率
      (A∩B)∪C=(A∪C)∩(B∪C)
      4.德摸根率(对偶率)(口诀:长杠变短杠开口变方向)
        —    -    -
      (A∩B)= A  ∪ B
      
      都发生用∩
      或者  ∪
      
      
      
      ```
   
      
   
   3. 概率的定义与性质
   
      ```perl
      1. 概率的统计性定义
      频率:设E是一个随机的实验,A是任意事件,重复n次实验,发生A事件的次数Na则称为A发生的频率
      概率:当实验次数n充分大时,频率趋近于一个常数p,常数p为A发生的事件.
      
      2.概率的性质
      1) 非负性 0<=P(A)<=1
      2规范性
      p(Ω)=1 p(Φ)=0
      3.有限可加性
      若A,B互斥, 则p(A∪B)=p(A)+p(B)
      4. 互补性
      p(A¯)=1-P(A)
      
      3. 重要公式
      1)减法公式
      p(A-B)=pA-P(AB)
      P(AB¯)=PA-P(AB)
      2)加法公式
      p(A∪B)=P(A)+P(B)-P(AB)
      如果A∩B=Φ 没有交集
      则:
      p(A∪B)=P(A)+P(B)
      p(A∪B∪C)=p(A)+p(B)+p(c)-P(AB)-P(AC)-P(BC)+P(ABC)(口诀:加奇减偶)
      
      
      注意: AB∈A   AB一定是A的子集
      
      
      
      
      
      p(A)¹A¯ —   
       
      ```
   
      
   
   4. 古典概型
   
      ```perl
      1. 古典概型的特点
      1)有限性: 实验的样本数是有限集合. Ω={e1,e2,e3,en}
      2)等可能性 p(e1)=p(e2)=1/n,所有样本点的概率都是相等的
      如 投掷筛子,Ω={1,2,3,4,5,6}
      p(1)=p(2)=1/6
      2.计算公式
      p(A)=A事件含样本点数/Ω含样本点个数
      如: 奇数点事件 A={1,3,5} P(A)=3/6=1/2
      
      排列和组合问题:
      有四样玩具1,2,3,4,从中任选2个,有几种取法
      (1,2) (1,3) (1,4) (2,3) (2,4) (3,4) 共6种
      c2,4=4*3/2*1=6
      c2,11=11*10/2*1
      
      排列问题:
      (1,2)
      (3,4)
      上面数分别取一个组合,有几种组合法
      (1,3) (1,4) (2,3) (2,4)
      公式:
      c1,2*C1,2=2*2=4
      ```
   
      
   
   5. 几何概型
   
      ```perl
      1. 几何概型特点:
      1)样本空间与几何区域有关(线段,平面,立体)
      2)等可能性,向样本空间内任意投一点,落在区域内任何一点的可能性相等
      
      p(A)=A的长度,面积,体积/ Ω的长度,面积,体积
      
      ```
   
      
   
   6. 条件概率与乘法公式
   
      ```perl
      1.条件概率: A事件发生时,B事件发生的概率
      P(B|A)=p(AB)/p(A)
      P(Ω|A)=1  p(Φ|A)=0
      
      2.
      p(B¯|A)=1-p(B|A)
      p(B¯|C)=1-p(B|C)
      
      3.p(B∪C|A)=p(B|A)+P(C|A)-P(BC/A)
      
      5. p(B-C|A)=p(B|A)-p(BC|A)
      
      6.  乘法公式
      p(AB)=P(A)P(B|A)
      P(ABC)=P(AB)P(C|AB)=P(A)P(B|A)P(C|AB)
      记忆: A先发生 p(A),B发生,但是A已经发生 P(B|A),依次类推.
      ```
   
      
   
   7. 全概率和贝叶斯公式
   
      ```c++
      1. 完备事件组的概念(划分)
      设A1,A2,A3,为Ω的事件组,满足的条件
      1)A1,A2,A3两两互斥 2) A1∪A2∪A3=Ω
        
      2.全概率公式
        P(B)=P(BA1)+P(BA2)+P(BA3)+P(BAn)
        P(B)=P(B|A1)*PA1+P(B|A2)*PA2+P(B|An)*P(An)
        把一个复杂事件转换成若干个小划分事件,及其条件概率.
      3.贝叶斯公式
        设B为任意一个事件,A1,A2,A3,An为Ω的一个完备事件组,
        含义:已知B发生的条件下,Aj(小划分事件)发生的条件概率
        
        P(A|B)=P(B|A)*p(A)*/P(B)
          
        利用全概公式,贝叶斯公式时,如何找Ω划分
          1)把实验分成两个阶段,把第一个阶段的所有可能结果A1,A2,..An看成Ω划分
          2)把B看成实验的结果,再把导致B发生的若干个原因看成Ω划分.
          
        甲 白 n 红 m
        已 白 N 红 M
         Ω划分:
      把第一阶段所有可能的结果看成Ω划分
        第一阶段: 从甲取一个球放入已中
          设 A1="从甲中取得白球"
             A2="从甲中取红球"
          B="从已中取到白球的概率"
          全概公式:P(B)=P(A1)P(B|A1)+P(A2)P(B|A2)
            
            (n/m+n*(N+1))/(M+N+1)+(m/m+n)*(N/M+N+1)
          
        
        
      ```
   
      
   
   8. 事件独立性
   
      ```perl
      若两个事件A,B 满足P(B|A)=P(B),那么事件A和事件B相互独立
      独立本质是A与B互不影响.
      P(A|B)=P(A)
      从条件概率的角度理解就是在条件B的情况下,A发生的概率与之前相比不变
      
      P(AB)=P(A)*P(B)
      实验次数不同,互斥是一次实验下出现的不同事件,
      独立事件,是两次或者多次实验出现的不同时间.
      ```
   
      
   
   9. 伯努利概型
   
      
      
      ```perl
      1.伯努利实验
      当实验的结果只有两种可能结果A和A¯,称为伯努利实验
      如,抛一枚硬币
      n重伯努利,把伯努利重复的进行n次
      
      伯努利三要素:1) n重独立 2)两种结果A和A¯ 3)每次实验P(A)=p
   
      ```
   
       ![image-20240104173640429](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240104173640429.png)
   
   10. 随机变量
   
       ```perl
       随机变量:随机实验的每一结果都对应着变量X的一个确定取值,因此随机变量X是样本空间S上的函数
       X=X(e) (e∈S)
       
       X(e)=2
       定义好随机变量后,就可以用随机变量的取值情况来刻画随机事件
       {X(e)=2}={X=2}
       代表黑球取2,对应的样本点的集合(样本点的子集称为随机事件)
       {x<=500}
       
       x取值可以是可列无穷多 .如数车辆个数
       x取值也可以是不可列无穷多.灯泡的寿命
       在样本空间中可以定义多个随机变量
       
       
       ```
   
       
   
   11. 离散型随机变量的定义(分布率,性质)
   
       ```perl
       离散型:如果随机变量的取值是有限个,或者是无限可列,称为离散随机变量
       设随机变量x的取值为:
       x1,x2,x3,x4..xn
       对应概率为
       P{x=xn}=pn
       称为离散型随机变量的x的分布律
       分布律的性质:
       1)对任意的自然数n 有pn>=0
       2)Σpn=1
       
       随机变量的分布率
       解题步骤:先找X变量的取值范围,在找相应值的概率
       
       
       
       ```
   
        ![image-20240105115713264](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240105115713264.png)
   
   12. 二项式分布
   
       ```perl
       bernoulli分布称为0,1 分布或者两点分布
       进行一次bernoulli实验,A是随机事件(如正面)
       P(A)=p p(A) p(A¯)=1-p
       设X表示这次实验总事件A发生的次数
       X=1 事件A发生
       X=0 事件A不发生
       
       二项分布
       进行n重bernoulli实验,A是随机事件,在每次实验中
       P(A)=p p(A) p(A¯)=1-p
       令x表示n重bernoulli 实验中A发生的次数
       x取值可能为0,1,2,3,4,5,6..n
       则称随机变量x服从参数(n,p)的二项式分布
       X ～B(n,p)
       
       如射击,命中为A事件
       做一次bernoulli,命中次数X=1
       不命中 x=0
       x表示什么就二项式分布了.命中次数
       
       二项式中, 做n次射击,x表示命中次数
       
       X ～B(5,1/4)
       
       做大可能值是
       (n+1)p :如果做12次 ,(12+1)*0.5=6次
       就是说做12次6次产生A事件(大概率)
       也就是说X=6,(12次实验,6次发生A事件)概率最高
       (n+1)p不是整数  k0=[(n+1)p ]
       ```
   
       
   
   13. 分布函数的定义
   
       ```perl
       F(x)=P{X<=x}
       称为X的分布函数
       含义是X 落在x左侧的概率是多少
       ```
   
       
   
   14. 连续随机变量
   
       ```perl
       对于随机变量X的分布函数,F(X),存在一个非负函数f(x)
       X称为连续变量,f(x)称为概率密度函数,简称概率密度
       连续性随机变量落在一个区间的概率是 密度函数做积分
       ```
   
       
   
   15. 
   
       
   
   50. 附图
   
       1.分配率推到图
   
        ![image-20240103152831068](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103152831068.png)
   
       2.概率的减法公式
   
        ![image-20240103152726665](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103152726665.png)
   
        
   
       3.德摸推到
   
        ![image-20240103141409938](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103141409938.png)
   
       4.排列组合算法
   
        ![image-20240103173210856](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103173210856.png)
   
       5.取小球案例
   
        ![image-20240103174549375](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103174549375.png)
   
       6.例题2
   
        ![image-20240103175837499](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240103175837499.png)
   
       7.事件组图
   
        ![image-20240104115126399](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240104115126399.png)
   
       8.完备事件组图
   
        ![image-20240104134510972](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240104134510972.png)
   
       
   
       
   
       
   

二 机器学习

1.  下载,安装python

2. 下载安装Anaconda

   ```perl
   下载地址:
   https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/
   ```

   

3. 新建开发环境,安装jupyter-notebook

   ```perl
   配置: conda create -n ai (创建虚拟环境)
   配置  conda activate ai(激活虚拟环境)
   ```

   

4. 安装jupterter

   ```pel
   进入conda 界面,进行安装
   ```

   

5. 安装matplotlib numpy pandas

   ```perl
   pip install matplotlib  -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
   
   ```

   

6. matplotlib使用

   ```python
   import matplotlib
   matplotlib.use('TkAgg')
   from matplotlib import pyplot as plt
   import numpy as np
   
   # Press the green button in the gutter to run the script.
   if __name__ == '__main__':
   
   
   
       #matplot
       plt.figure()
       # zorder控制绘图顺序
       x=[1,2,3,4,5]
       y=[2,3,4,5,6]
       #直线图
       # plt.plot(x, y)
       #散点图
       plt.scatter(x,y)
   
       plt.title('line')
       plt.xlabel('x')
       plt.ylabel('y')
   
       plt.show()
   
   ```

   

7. numpy安装使用

   ```perl
   if __name__ == '__main__':
       a=np.eye(5)
       print(a)
   ```

   

8. pandas 安装和使用

   ```perl
   #pandas 中文文档
   https://www.pypandas.cn/docs/reference.html
   ```

   

   ```perl
   pip install pandas  -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
   ```

   ```perl
   import pandas as pd
   # Press the green button in the gutter to run the script.
   if __name__ == '__main__':
       data=pd.read_csv('data.csv')
   ```

   

二 线性回归

1. 什么是机器学习

   ```perl
   从数据中寻找规律,建立关系,根据建立的关系去解决问题.
   应用场景:
   数据挖掘
     机器视觉
     自然语言处理
     证劵分析
     
   ```

   

1. 监督学习和无监督学习

   ```perl
   监督学习: 训练的数据包含正确的结果
   无监督学习: 训练的数据不包括正确的结果
   半监督学习:训练数据包含少量的正确的结果
   强化学习: 根据每次结果收获奖惩,进行学习,实现优化
   
   ```

   

2. 线性回归

   ```perl
   1)回归分析:根据数据,确定两种或者两种以上变量间相互依赖的定量关系
   步骤:
   1. 确定P和A直接的定量关系
   P=f(A)
   线性模型:
   y=ax+b
   求合理的a和b
   
   minimize{1/2mΣ(y'i-yi)²
   
   2)scikit-learn
   是针对机器学习一套开源库
   3)模型评估(越小越好)
   MSE=1/mΣ(y'i-yi)²
   R方值
   R²=Σ(y'i-yi)²/Σ(yi-yi¯)²=1-MSE/方差(越接近1,越好)
   ```

   回归梯度下降

    ![image-20240108160513633](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240108160513633.png)

3. 线性回归实战

   ```perl
   #安装scikit-learn 
   pip install scikit-learn  -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
   ```

   代码实现

   ```python
   
   import pandas as pd
   import matplotlib
   matplotlib.use('TkAgg')
   import numpy as np
   import matplotlib.pyplot as plt
   from sklearn.metrics import mean_squared_error,r2_score
   from sklearn.linear_model import LinearRegression
   if __name__ == '__main__':
       data=pd.read_csv('data/generated_data.csv')
       print(data)
       # print(data.shape)
   
       #取值
       x=data.loc[:,'x']
       y = data.loc[:, 'y']
       print(x)
   
   #画布大小
       # plt.figure()
       # plt.scatter(x,y)
       # plt.show()
   
       #获取scikitlearn模型
       lr_model = LinearRegression()
   
       x=np.array(x)
       y=np.array(y)
   
       #变成2维数组,变成10行1列
       x=x.reshape(-1,1)
       y=y.reshape(-1,1)
       lr_model.fit(x, y)
       # pre=lr_model.predict([[3.5]])
       y_pre=lr_model.predict(x)
       # print(pre)
   
       #打印 a,b
       #函数为y=2x+5
       a=lr_model.coef_
       b=lr_model.intercept_
       print(a)
       print(b)
   
       #测试是不是完美的拟合
       #mse 趋近于零
       #R方值 等于1
       #上述条件为最好
   
       MSE=mean_squared_error(y,y_pre)
       R2=r2_score(y,y_pre)
       print("查看模型")
       print(MSE,R2)
   
       #画一下图
       plt.scatter(y,y_pre)
       plt.show()
   
   
   
   ```

   

5. 多因子线性回归

   ```python
   import pandas as pd
   import matplotlib
   matplotlib.use('TkAgg')
   import numpy as np
   import matplotlib.pyplot as plt
   from sklearn.metrics import mean_squared_error,r2_score
   from sklearn.linear_model import LinearRegression
   if __name__ == '__main__':
       house_data=pd.read_csv('data/usa_housing_price.csv')
       print(house_data.head())
       #画图
       fig=plt.figure()
       #第一个图
       fig1=plt.subplot(231)
       plt.title("Price vs income")
       plt.scatter(house_data.loc[:,"Avg. Area Income"],house_data.loc[:,"Price"])
       #第二个图
       fig1 = plt.subplot(232)
       plt.title("Price vs House Age")
       plt.scatter(house_data.loc[:, "Avg. Area House Age"], house_data.loc[:, "Price"])
   
   
       # 第三个图
       fig1 = plt.subplot(233)
       plt.title("Price vs Number of Rooms")
       plt.scatter(house_data.loc[:, "Avg. Area Number of Rooms"], house_data.loc[:, "Price"])
   
       # 第四个图
       fig1 = plt.subplot(234)
       plt.title("Price vs Population")
       plt.scatter(house_data.loc[:, "Area Population"], house_data.loc[:, "Price"])
   
       # 第五个图
       fig1 = plt.subplot(235)
       plt.title("Price vs House size")
       plt.scatter(house_data.loc[:, "size"], house_data.loc[:, "Price"])
       # plt.show()
        #一元回归
       LR1= LinearRegression()
       x=house_data.loc[:,"size"]
       y=house_data.loc[:,"Price"]
       x=np.array(x)
       y=np.array(y)
       x=x.reshape(-1,1)
       y=y.reshape(-1,1)
       print(x.shape)
       LR1.fit(x,y)
       y_pre=LR1.predict(x)
       m1=mean_squared_error(y,y_pre)
       r1=r2_score(y,y_pre)
       print(m1,r1)
   
       fig6=plt.figure()
       plt.scatter(x,y)
       plt.plot(x,y_pre,'r')
       # plt.show()
   
       #多因子
       #数据处理
       x_data=house_data.drop("Price",axis=1)
       print(x_data)
   
       LR_multi=LinearRegression()
       LR_multi.fit(x_data,y)
       multi_y=LR_multi.predict(x_data)
       multi_mean=mean_squared_error(y,multi_y)
       multi_r2=r2_score(y,multi_y)
       print(multi_mean,multi_r2)
       #画图看是否集中
       
       fig8=plt.figure()
       plt.scatter(y, multi_y)
       plt.show()
   
   
   
   ```

三 逻辑回归

1. 分类任务

   ```perl
   1)根据数据,采用线性回归得出数学公式
   Y=0.1364x+0.5
   y=f(x){
    1, Y>=0.5
    0  Y<0.5
   }
   
   2)局限性,数据量大的时候,很不准
   当x距离远点变远,预测开始不准确
   
   逻辑回归
   公式:
   1)Y=1/1+e-x
   2)y=f(x){
    1, Y>=0.5
    0  Y<0.5
   }
   ```

    ![image-20240109145111110](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240109145111110.png)

    ![image-20240109153838559](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240109153838559.png)

    ![image-20240112104755089](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240112104755089.png)

    ![image-20240112105013019](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240112105013019.png)

2. 逻辑回归

   ```perl
   import pandas as pd
   import numpy as np
   from matplotlib import pyplot as plt
   import matplotlib
   matplotlib.use('TkAgg')
   
   from sklearn.linear_model import  LogisticRegression
   from sklearn.metrics import accuracy_score
   if __name__ == '__main__':
       #步骤: 1) 画图  2) fit 模型训练 3) predict 模型预测 4) metric 模型验证 5) 画出边界线
       data=pd.read_csv('data/examdata.csv')
   
       #add label mask
       mask=data.loc[:,"Pass"]==1
   
   
    #mask 显示和不显示散点,true显示,false 不显示
   
       # print(mask)
       # passed=plt.scatter(data.loc[: ,"Exam1"][mask], data.loc[: ,'Exam2'][mask])
       # failed=plt.scatter(data.loc[: ,"Exam1"][~mask], data.loc[: ,'Exam2'][~mask])
       # plt.legend((passed,failed),("pass","fail"))
       # plt.title("Exam1-exam2")
       # plt.xlabel("Exam1")
       # plt.ylabel("Exam2")
       # plt.show()
       # 2)逻辑回归训练
   
       x=data.drop(["Pass"],axis=1);
       y=data.loc[:,"Pass"]
       x1=data.loc[:,"Exam1"]
       x2=data.loc[:,"Exam2"]
       LR=LogisticRegression()
   
       LR.fit(x,y)
   
       # 3) 预测结果 predict
       y_predict=LR.predict(x)
       # print(y_predict)
   
       # 4) 评估模型的准确性
       #评估对的结果/总样本
       result=accuracy_score(y,y_predict)
       print(result)
   
       # 5) 预测未来的结果
       y_test=LR.predict([[70,65]])
       print('passed' if y_test==1 else 'failed')
   
       # 6) 获取theta值
       # 边界函数如下:
       # 20535491217790366x1+0.2005838039546903x2-25.05219314=0
       #边界函数 φ0+φ1x1+φ2x2=0
   
       theta0=LR.intercept_
       print(theta0)
       theta1,theta2=LR.coef_[0][0],LR.coef_[0][1]
       print(theta0,theta1,theta2)
   
       # 7)画出边界线
       x2_new=-(theta1*x1+theta0)/theta2
       fig2=plt.figure()
       passed = plt.scatter(data.loc[:, "Exam1"][mask], data.loc[:, 'Exam2'][mask])
       failed = plt.scatter(data.loc[:, "Exam1"][~mask], data.loc[:, 'Exam2'][~mask])
       plt.legend((passed, failed), ("pass", "fail"))
       plt.title("Exam1-exam2")
       plt.xlabel("Exam1")
       plt.ylabel("Exam2")
   
       #画出边界线
       plt.plot(x1,x2_new)
       plt.show()
   
   ```

   

3. 二阶函数模型的逻辑回归

   ```perl
   import pandas as pd
   import numpy as np
   from matplotlib import pyplot as plt
   import matplotlib
   matplotlib.use('TkAgg')
   
   from sklearn.linear_model import  LogisticRegression
   from sklearn.metrics import accuracy_score
   if __name__ == '__main__':
       #步骤: 1) 画图  2) fit 模型训练 3) predict 模型预测 4) metric 模型验证 5) 画出边界线
       #画出更好的边界线
   
       #边界函数
       # θ0+θ1x1+θ2x2=0(边界函数)
       # 二阶边界函数
       # θ0+θ1x1+θ2x2+θ3x1²+θ4x2²+θ5x1x2=0
       
        #首先将边界函数θ0+θ1x1+θ2x2+θ3x1²+θ4x2²+θ5x1x2=0,转换为 ax²+bx+c=0形式
   
       # θ4x2²+(θ5x1+θ2)x2+(θ0+θ1x1+θ3x1²)
       # x2=(-b+(b²-4ac))/2a
   
   
       data=pd.read_csv('data/examdata.csv')
   
       #add label mask
       mask=data.loc[:,"Pass"]==1
       #创建新的数据
       x1 = data.loc[:, "Exam1"]
       x2 = data.loc[:, "Exam2"]
       y = data.loc[:, "Pass"]
       x1_2=x1*x1
       x2_2=x2*x2
       x1_x2=x1*x2
       x_new={'x1':x1,'x2':x2,'x1_2':x1_2,'x2_2':x2_2,'x1_x2':x1_x2}
       x_new=pd.DataFrame(x_new)
   
       #模型训练
       LR2=LogisticRegression();
       LR2.fit(x_new,y)
       #模型预测
       y_predict=LR2.predict(x_new)
       #模型打分
   
       resut=accuracy_score(y,y_predict)
       print(resut)
       #画出曲线图
      
       x1_new = x1.sort_values()
       theta0=LR2.intercept_
       theta1,theta2,theta3,theta4,theta5=LR2.coef_[0][0],LR2.coef_[0][1],LR2.coef_[0][2],LR2.coef_[0][3],LR2.coef_[0][4]
       a=theta4
       b=theta5*x1_new+theta2
       c=theta0+theta1*x1_new+theta3*x1_new*x1_new
       x2_new=(-b+np.sqrt(b*b-4*a*c))/(2*a)
       print(x2_new)
   
       #画图
       fig2 = plt.figure()
       passed = plt.scatter(data.loc[:, "Exam1"][mask], data.loc[:, 'Exam2'][mask])
       failed = plt.scatter(data.loc[:, "Exam1"][~mask], data.loc[:, 'Exam2'][~mask])
       plt.legend((passed, failed), ("pass", "fail"))
       plt.title("Exam1-exam2")
       plt.xlabel("Exam1")
       plt.ylabel("Exam2")
   
       # 画出曲面图
       plt.plot(x1_new,x2_new)
   
       plt.show()
   
   ```

   

三 无监督学习

```perl
1. KMeans KNN Mean
定义:
标记过的训练数据:有输入数据,并有正确的答案
是机器学习的一种,没有给定事先标记过的训练数据,自动对输入的数据分类或者分群
优点:
1)算法不受监督信息约束,可能发现新的信息
2)不需要标签数据,极大程度扩大样本数据
应用最广: 聚类分析
聚类分析:根据属性的相似度,自动划分成不同的类别

kmeans 算法:
k 均值聚类:
以空间中k个点为中心进行聚类,对最靠近他们的对象归类
公式:
1)数据点与各族中心点的距离dist(xi,uj)
uj为第j区域中心
2)根据距离归类 ui距离那个区域中心点最近,就归于那个区域
3)更新中心点 

k值聚类算法流程
1) 选择聚类的个数k
2) 确定聚类的中心
3) 根据点到聚类的中心,划分成k个类别
4) 划好类别后,更新聚类中心
5)重复以上步骤直到收敛(中心点不在变化)

均值漂移聚类
一种基于密度梯度上升的聚类算法


```

 ![image-20240112181935291](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240112181935291.png)

 ![image-20240115103835180](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240115103835180.png)

 ![image-20240115115201684](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240115115201684.png)

1. Kmeans 算法

   ```perl
   import pandas as pd
   import numpy as np
   from matplotlib import pyplot as plt
   import matplotlib
   matplotlib.use("TkAgg")
   from sklearn.metrics import accuracy_score
   from sklearn.cluster import KMeans
   
   if __name__ == '__main__':
       data=pd.read_csv('data/data.csv')
       x=data.drop(['labels'],axis=1)
       y=data.loc[:,"labels"]
   
       #查看一下y数据的类别
       re=pd.value_counts(y)
       # print(re)
   
       #画图展示数据
   
   
   
       #使用Kmens
       KM=KMeans(n_clusters=3,random_state=0)
       KM.fit(x)
       centes=KM.cluster_centers_
   
       # fig1 = plt.figure()
       # x1 = data.loc[:, "V1"]
       # x2 = data.loc[:, "V2"]
       #
       # lable0 = plt.scatter(x1[y == 0], x2[y == 0])
       # lable1 = plt.scatter(x1[y == 1], x2[y == 1])
       # lable2 = plt.scatter(x1[y == 2], x2[y == 2])
       #
       # plt.scatter(centes[:,0],centes[:,1])
       # plt.legend((lable0, lable1, lable2), ('label0', 'label1', 'lable2'))
       # plt.title("Kmeans")
       # plt.xlabel("x1")
       # plt.ylabel("x2")
   
   
       #验证类别
       y_dict_test=KM.predict([[80,60]]);
   
       #验证评分
       y_dict=KM.predict(x)
   
       fig1 = plt.subplot(131)
       x1 = data.loc[:, "V1"]
       x2 = data.loc[:, "V2"]
   
       lable0 = plt.scatter(x1[y == 0], x2[y == 0])
       lable1 = plt.scatter(x1[y == 1], x2[y == 1])
       lable2 = plt.scatter(x1[y == 2], x2[y == 2])
   
       plt.scatter(centes[:, 0], centes[:, 1])
       plt.legend((lable0, lable1, lable2), ('label0', 'label1', 'lable2'))
       plt.title("Kmeans")
       plt.xlabel("x1")
       plt.ylabel("x2")
   
   
   
   
       y_corrected=[]
   
       for i in y_dict:
           print(i)
           if(i==0):
               y_corrected.append(2)
           if(i==1):
               y_corrected.append(1)
           if(i==2):
               y_corrected.append(0)
       print(pd.value_counts(y_dict),pd.value_counts(y_corrected),pd.value_counts(y))
   
   
       fig2 = plt.subplot(132)
       x1 = data.loc[:, "V1"]
       x2 = data.loc[:, "V2"]
   
       lable0 = plt.scatter(x1[y_dict == 0], x2[y_dict == 0])
       lable1 = plt.scatter(x1[y_dict == 1], x2[y_dict == 1])
       lable2 = plt.scatter(x1[y_dict == 2], x2[y_dict == 2])
   
       plt.scatter(centes[:, 0], centes[:, 1])
       plt.legend((lable0, lable1, lable2), ('label0', 'label1', 'lable2'))
       plt.title("predict")
       plt.xlabel("x1")
       plt.ylabel("x2")
   
       fig2 = plt.subplot(133)
       x1 = data.loc[:, "V1"]
       x2 = data.loc[:, "V2"]
   
       #要想y_corrected 能用y_corrected==0方式,
       #必须用np.array转换
       y_corrected=np.array(y_corrected)
       lable0 = plt.scatter(x1[y_corrected == 0], x2[y_corrected == 0])
       lable1 = plt.scatter(x1[y_corrected == 1], x2[y_corrected == 1])
       lable2 = plt.scatter(x1[y_corrected == 2], x2[y_corrected == 2])
   
       plt.scatter(centes[:, 0], centes[:, 1])
       plt.legend((lable0, lable1, lable2), ('label0', 'label1', 'lable2'))
       plt.title("predict")
       plt.xlabel("x1")
       plt.ylabel("x2")
       plt.show()
   
       #验证
   
       print(accuracy_score(y,y_corrected))
   
   ```

   

2. KNN

   ```perl
   
   import pandas as pd
   import numpy as np
   from sklearn.neighbors import KNeighborsRegressor
   from sklearn.metrics import accuracy_score
   from matplotlib import pyplot as plt
   import matplotlib
   matplotlib.use("TkAgg")
   if __name__ == '__main__':
       data=pd.read_csv('data/data.csv')
       Knn=KNeighborsRegressor(n_neighbors=3)
       x=data.drop(['labels'],axis=1)
   
       Knn.fit(x,data.loc[:,'labels'])
       y_predict_test=Knn.predict([[80,60]])
       print(y_predict_test)
        #评估模型得分
       y_predict=Knn.predict(x);
       print(y_predict)
   
       y=data.loc[:,"labels"]
   
       y_predict=np.array(y)
     
   
       score=accuracy_score(y,y_predict)
       print(score)
   
   
   
   ```

   

3. MeanShift

   ```perl
   
   import pandas as pd
   import numpy as np
   from sklearn.neighbors import KNeighborsRegressor
   from sklearn.metrics import accuracy_score
   from matplotlib import pyplot as plt
   from sklearn.cluster import MeanShift,estimate_bandwidth
   import matplotlib
   matplotlib.use("TkAgg")
   if __name__ == '__main__':
       data=pd.read_csv('data/data.csv')
       x = data.drop(['labels'], axis=1)
       bw=estimate_bandwidth(x,n_samples=500)
       print(bw)
   
       MF=MeanShift(bandwidth=bw)
       MF.fit(x)
       y_dict=MF.predict(x)
       print(pd.value_counts(y_dict))
   
   ```

   

4. 决策树

   ```perl
   一种对实例进行分类的树形结构,通过多层判断区分目标所属的类型
   问题核心:特征选择,每一个节点,应该选用哪个节点.
   三种求解的方法
   ID3 C4.5 CART
   
   ID3:利用信息熵原理选择信息增益最大的属性作为分支,递归的拓展决策树的分支
   
   ```

    ![image-20240115162555559](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240115162555559.png) 

5. ![image-20240115164607535](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240115164607535.png)![image-20240115171859975](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240115171859975.png)

6. 异常监察

   ```perl
   对输入的数据,对不符合预期模式的数据进行识别
   ```

   

    ![image-20240116102550750](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116102550750.png)

8. ![image-20240116102844204](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116102844204.png)

9. ![image-20240116103204171](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116103204171.png)

10. ![image-20240116103524856](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116103524856.png)

11. 主成分分析(pca降维)

12. ![image-20240116110030344](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116110030344.png)

12. 数据降维的方法pca

    ![image-20240116111227527](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116111227527.png)

13. ![image-20240116111800694](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116111800694.png)

14. 决策树的含义

     ![image-20240116132036745](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116132036745.png)

    ```perl
    四行数据所代表的含义：
    
    第一行X[3]<=0.75：鸢尾花数据集的特征集有4 个属性，所以对于X[n]中的n的取值范围为0<=n<=3，X[0] 表示第1个属性，X[3] 表示第4 个属性。X[3]<=0.75 的意思就是当X[3] 属性的值小于等于0.75 的时候，走左子树，否则走右子树。
    
    X[0] 表示花萼长度。
    
    X[1] 表示花萼宽度。
    
    X[2] 表示花瓣长度。
    
    X[3] 表示花瓣宽度。
    
    第二行gini=0.666，表示当前的gini 系数值。
    
    第三行samples=100，samples 表示当前的样本数。
    
    我们知道整个数据集有150 条数据，我们选择了0.33 百分比作为测试集，那么训练集的数据就占0.67，也就是100 条数据。
    
    根节点包含所有样本集，所以根节点的 samples 值为100。
    
    第四行value：value 表示属于该节点的每个类别的样本个数，value 是一个数组，数组中的元素之和为samples 值。我们知道该数据集的目标集中共有3 个类别，分别为：setosa，versicolor 和 virginica。所以：
    
    value[0] 表示该节点中setosa 种类的数据量，即34。
    
    value[1] 表示该节点中versicolor 种类的数据量，即31。
    
    value[2] 表示该节点中virginica 种类的数据量，即35。
    ```

    

     ![image-20240116132120622](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240116132120622.png)

15. 决策树的代码

    ```perl
    import pandas as pd
    import numpy as np
    from matplotlib import pyplot as plt
    import matplotlib
    matplotlib.use("TkAgg")
    from sklearn.metrics import accuracy_score
    from sklearn.cluster import KMeans
    from sklearn import tree
    import time
    if __name__ == '__main__':
        data=pd.read_csv('data/iris_data.csv')
        print(data.head)
        x=data.drop(['target','label'],axis=1)
        y=data.loc[:,'label']
        # print(x.shape,y.shape)
    
        #创建模型
        dc_tree=tree.DecisionTreeClassifier(criterion='entropy',min_samples_leaf=1)
        dc_tree.fit(x, y)
    
        #评估模型的表现
        y_predict=dc_tree.predict(x)
    
        score=accuracy_score(y,y_predict)
        print(score)
    
        #可视化模型结构
    
        fig=plt.figure(figsize=(10,10))
        tree.plot_tree(dc_tree,filled=True,feature_names=['SepaLenght','SepaWidth','PetaLength','PetaWidth'],class_names=['setosa','versicolor','virginica'])
        plt.show()
    
    
    ```

    

16. 异常点检测

    ```perl
    import pandas as pd
    import numpy as np
    from matplotlib import pyplot as plt
    import matplotlib
    matplotlib.use("TkAgg")
    from scipy.stats import norm
    from sklearn.covariance import EllipticEnvelope
    from sklearn.metrics import accuracy_score
    from sklearn.cluster import KMeans
    from sklearn import tree
    import time
    
    #数据异常检测
    if __name__ == '__main__':
    
        data=pd.read_csv('data/anomaly_data.csv')
        x1=data.loc[:,'x1']
        x2=data.loc[:,'x2']
    
    
        #画出数据的直方图
        fig2=plt.figure()
        plt.subplot(121)
        plt.hist(x1,bins=100)
        plt.title("x1 distribute")
        plt.xlabel("x1")
        plt.ylabel("counts")
    
        plt.subplot(122)
        plt.hist(x2, bins=100)
        plt.title("x2 distribute")
        plt.xlabel("x2")
        # plt.ylabel("counts")
    
    
    
        #计算x1 的均值和标准差
        x1_mean=x1.mean()
        x1_sigma=x1.std()
        print(x1_mean,x1_sigma)
    
        # 计算x2 的均值和标准差
        x2_mean = x2.mean()
        x2_sigma = x2.std()
        print(x2_mean, x2_sigma)
    
        #计算高斯密度函数
        x1_range=np.linspace(0,20,300)
        x1_normal=norm.pdf(x1_range,x1_mean,x1_sigma)
    
        x2_range = np.linspace(0, 20, 300)
        x2_normal = norm.pdf(x2_range, x2_mean, x2_sigma)
    
    
        fig5=plt.figure(figsize=(20,5))
        plt.title("gao si")
        # plt.subplot(121)
        plt.plot(x1_range,x1_normal)
        # plt.subplot(122)
        plt.plot(x2_range,x2_normal)
        plt.show()
    
        #异常监测
        #模型训练
        ad_model=EllipticEnvelope()
        ad_model.fit(data)
        y_predict=ad_model.predict(data)
    
        print(pd.value_counts(y_predict))
    
        #展示异常的点
    
        fig6=plt.figure(figsize=(20,10))
        plt.xlabel("x1")
        plt.ylabel("x2")
        plt.scatter(x1, x2,marker='x')
        plt.scatter(x1[y_predict==-1],x2[y_predict==-1],marker='o',facecolor='none',edgecolors='red')
    
        plt.show()
    
    
    ```

    

17. pca 主成分分析

     ![image-20240117104034212](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117104034212.png)

    ```perl
    #数据标准化,均值为0,标准差为1
    #pca 降维之后,主成分方差的比例是多少,取比例大的
    import pandas as pd
    import numpy as np
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score
    from sklearn.preprocessing import StandardScaler
    from matplotlib import pyplot as plt
    from sklearn.decomposition import PCA
    import matplotlib
    matplotlib.use("TkAgg")
    if __name__ == '__main__':
        data = pd.read_csv('data/iris_data.csv')
        x = data.drop(['target', 'label'], axis=1)
        y = data.loc[:, 'label']
        KNN=KNeighborsClassifier(n_neighbors=3)
        KNN.fit(x,y)
        y_predict=KNN.predict(x)
    
    
        # 评估模型的表现
    
    
        score = accuracy_score(y, y_predict)
        print(score)
    
        #标准化数据(将均值设为0, 方差设为1)
        data_norm=StandardScaler().fit_transform(x)
        print(type(data_norm))
    
        #一个维度的直方图
        fig1=plt.figure(figsize=(10,10))
        plt.subplot(121)
        plt.hist(x.loc[:,'sepal length'],bins=100)
        plt.subplot(122)
        plt.hist(data_norm[:, 0], bins=100)
        plt.show()
    
        data_mean=data_norm[:,0].mean()
        data_std=data_norm[:,0].std()
        print(data_mean,data_std)
        # pca=PCA(n_components=4)
        # #对标准化数据进行pca 降维,取方差较大的,方差越大,越分散
        # pca.fit_transform(data_norm)
        # #降维之后方差的比例
        # radio=pca.explained_variance_ratio_
        # print(radio)
        #
        # #显示降维之后方差比例,方差比例小,数据相关度高,数据重复多,可以舍弃
        # fig5=plt.figure(figsize=(10,5))
        # plt.bar([1,2,3,4],radio)
        # plt.xticks([1,2,3,4],['PC1',"PC2","PC3","PC4"])
        # plt.show()
    
        #先插看原始降维,原来有4 ,其中两个方差比例很小,所以下方重新降维,选择2
        pca1=PCA(n_components=2)
        x_pca=pca1.fit_transform(data_norm)
    
        #显示降维后的数据
        fig8=plt.figure()
        setosa=plt.scatter(x_pca[:,0][y==0],x_pca[:,1][y==0])
        versicolor=plt.scatter(x_pca[:, 0][y == 1], x_pca[:, 1][y == 1])
        virginca=plt.scatter(x_pca[:, 0][y == 2], x_pca[:, 1][y == 2])
        plt.legend((setosa,versicolor,virginca),('setosa','versicolor','virginca'))
        plt.show()
    
    
    
    
    ```

    

18. 模型评价与优化

     ![image-20240117113133285](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117113133285.png)

    ```perl
    #1 过拟合
    
    抛物线回归
    r=θ0+θ1t+θt²
    
    欠拟合和过拟合
    模型不合适,导致其无法对数据实现有效的预测
    欠拟合: 可以通过训练数据发现
    过拟合:需要用预测数据发现(过拟合可能存在:训练数据准确,预测数据不准确)
    增加正则项
    
    如果
    
    ```

     ![image-20240117114352497](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117114352497.png)

19.  ![image-20240117115511492](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117115511492.png)

20. 数据分离与混淆矩阵

    ```perl
    1. 把数据分成两部分,训练数据,测试数据
    2.混淆矩阵
    accouraty_score:缺陷
    没有体现数据预测的实际分布情况
    没有提现错误的预测类型
    混淆矩阵(误差矩阵):用于衡量分类算法的准确程度
    ```

     ![image-20240117134317917](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117134317917.png)

    ![image-20240117135728806](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117135728806.png)

    ![image-20240117140258527](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117140258527.png)

21. 模型优化

    ```perl
    
    
    
    ```

    ![image-20240117140944134](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117140944134.png)

    ![image-20240117141138394](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117141138394.png)

    ![image-20240117143001523](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117143001523.png)

22.  ![image-20240117175151689](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240117175151689.png)

23. 二项式回归

    ```perl
    import pandas as pd
    import numpy as np
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import r2_score
    from sklearn.linear_model import LinearRegression
    from matplotlib import pyplot as plt
    from sklearn.preprocessing import PolynomialFeatures
    import matplotlib
    matplotlib.use("TkAgg")
    if __name__ == '__main__':
        data_train=pd.read_csv('data/T-R-train.csv')
        x_train=data_train.loc[:,"T"]
        y_train=data_train.loc[:,"rate"]
    
    
    
        #线性回归模型的预测
        line_md=LinearRegression()
        x_train=np.array(x_train).reshape(-1,1)
        line_md.fit(x_train,y_train)
    
        y_train_predict=line_md.predict(x_train)
        print(line_md.coef_)
        print(line_md.intercept_)
        score1=r2_score(y_train,y_train_predict)
    
    
    
    
    
    
        #计算r2 分数
    
        data_test = pd.read_csv('data/T-R-test.csv')
        x_test = data_test.loc[:, "T"]
        y_test = data_test.loc[:, "rate"]
        x_test=np.array(x_test).reshape(-1,1)
        y_test_predict=line_md.predict(x_test)
        score2=r2_score(y_test_predict,y_test)
    
    
        #画出线性回归的图
    
        x_range=np.linspace(40,90,300).reshape(-1,1)
        y_range=line_md.predict(x_range)
    
        # 可视化图形
        fig = plt.figure()
        plt.scatter(x_train, y_train)
        plt.plot(x_range,y_range)
        plt.xlabel("temperature")
        plt.ylabel("rate")
        plt.show()
    
        #多项式回归
        ploy2=PolynomialFeatures(degree=2)
        x2_train=ploy2.fit_transform(x_train)
        x2_test=ploy2.transform(x_test)
    
        lr2=LinearRegression()
        lr2.fit(x2_train,y_train)
        y2_predict=lr2.predict(x2_train)
        print(y2_predict)
        print(y_train)
        score4=r2_score(y2_predict,y_train)
    
        print(score4)
    
        # print(lr2.coef_[0][1])
    
        #画出二项式图
        fig6=plt.figure()
    
        x2_range = np.linspace(40, 90, 300).reshape(-1, 1)
    
    
        x2_range1=ploy2.transform(x2_range)
        y2_predict_test=lr2.predict(x2_range1)
        plt.plot(x2_range,y2_predict_test)
        print(y2_predict)
        plt.show()
        print(x2_range)
        # print(y2_predict_test)
    
    ```

    

24. 数据降维,knn 分类画出分类图,计算混淆矩阵

    ```perl
    import pandas as pd
    import numpy as np
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import r2_score
    from sklearn.linear_model import LinearRegression
    from matplotlib import pyplot as plt
    from sklearn.preprocessing import PolynomialFeatures
    from sklearn.covariance import EllipticEnvelope
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    import matplotlib
    from sklearn.model_selection import train_test_split
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import confusion_matrix
    matplotlib.use("TkAgg")
    if __name__ == '__main__':
        #基于踢出点的数据进行pca 处理
        data=pd.read_csv('data/data_class_processed.csv')
        x_data=data.drop(['y'],axis=1)
        y=data.loc[:, 'y']
        #标准化数据,均值0,方差为1
        data_normal=StandardScaler().fit_transform(x_data)
    
        # print(data_normal)
    
        print(data_normal[:,1].mean(),data_normal[:,1].std())
        pca=PCA(n_components=2)
        pca.fit_transform(data_normal)
        radio=pca.explained_variance_ratio_
    
        fig=plt.figure()
        plt.bar([1,2],radio)
        plt.show()
        print(radio)
    
        #进行数据分离(test_size test_size数据占总数据的比例)
        x_train,x_test,y_train,y_test=train_test_split(x_data,y,random_state=4,test_size=0.4)
        print(x_train.shape,x_test.shape,y_test.shape)
    
        #用分好训练数据和测试数据进行knn分类
        knn_10=KNeighborsClassifier(n_neighbors=10)
        knn_10.fit(x_train,y_train)
        y_train_predict=knn_10.predict(x_train)
        y_test_predict=knn_10.predict(x_test)
        score1=accuracy_score(y_train,y_train_predict)
        score2= accuracy_score(y_test, y_test_predict)
        print(score1,score2)
        #画出KNN的边界线
        xx,yy=np.meshgrid(np.arange(0,10,0.05),np.arange(0,10,0.05))
        x_range=np.c_[xx.ravel(),yy.ravel()]
        print(x_range)
        y_range_predict=knn_10.predict(x_range)
    
        #画出分界面
        fig6=plt.figure()
        bad=plt.scatter(x_range[:,0][y_range_predict==0],x_range[:,1][y_range_predict==0])
    
        good=plt.scatter(x_range[:, 0][y_range_predict == 1], x_range[:, 1][y_range_predict == 1])
        dash_bad=plt.scatter(data.loc[:, 'x1'][y == 0], data.loc[:, 'x2'][y == 0])
        dash_good=plt.scatter(data.loc[:, 'x1'][y == 1], data.loc[:, 'x2'][y == 1])
        plt.xlabel("x1")
        plt.ylabel("x2")
        plt.legend((bad,good,dash_bad,dash_good),('bad','good','dash_bad','dash_good'))
        plt.show()
    
        #测试混淆矩阵
        cm=confusion_matrix(y_test,y_test_predict)
        print(cm)
        TP=cm[1,1]
        TN=cm[0,0]
        FP=cm[0,1]
        FN=cm[1,0]
        #计算准确率
        Accuracy=(TP+TN)/(TP+TN+FP+FN)
        print(Accuracy)
        #计算灵敏度(正样本中,预测正确的比例)
        sensitivity=Recall=TP/(TP+FN)
        print(sensitivity)
        #特异度,负样本中预测的正确的比例
        specificity=TN/(TN+FP)
        print(specificity)
        #精确率
        precision=TP/(TP+FP)
        print(precision)
        #F1 分数 综合Precision和Recall 一个判断指标
        f1=2*precision*Recall/(precision+Recall)
        print(f1)
    ```

    

25. 深度学习--多层感知器

     ![image-20240118180002412](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240118180002412.png)

    ```perl
    多层感知器
    
    
    
    ```

     ![image-20240118181126208](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240118181126208.png)

    ![image-20240118181258365](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240118181258365.png)

    

    ![image-20240118181435243](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240118181435243.png)

    ![image-20240118182149974](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240118182149974.png)

     ![image-20240119112023480](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240119112023480.png)

     ![image-20240119114125598](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240119114125598.png)

    ![image-20240119135951528](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240119135951528.png)

    ![image-20240119140255245](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240119140255245.png)

26. 安装tensorFlow

    ```perl
    pip install tensorflow -i https://mirrors.aliyun.com/pypi/simple --ignore-installed
    ```

    ```perl
    
    #基于mlp的二分类问题
    
    import pandas as pd
    import numpy as np
    from matplotlib import pyplot as plt
    import matplotlib
    matplotlib.use("TkAgg")
    from sklearn.model_selection import train_test_split
    from keras.models import Sequential
    from keras.layers import Dense,Activation
    from sklearn.metrics import accuracy_score
    from keras.models import load_model
    
    if __name__ == '__main__':
        #1. 基于data.csv数据,建立mlp模型,计算在测试数据上准确率,可视化预测结果
        #1. 数据分离: test_size=0.33 random_state=10
        #模型结构,一层隐藏层 有20个神经元
    
        data = pd.read_csv('data/data.csv')
        x=data.drop(["y"],axis=1)
        y=data.loc[:,'y']
    
        #可视化数据
        plt.figure(figsize=(5,5))
        passed=plt.scatter(data.loc[:,'x1'][y==1],data.loc[:,'x2'][y==1])
        faild = plt.scatter(data.loc[:, 'x1'][y == 0], data.loc[:, 'x2'][y == 0])
        plt.xlabel("x1")
        plt.ylabel("x2")
        plt.legend((passed,faild),("pass","fail"))
        # plt.show()
    
        #数据分离
        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=10)
        print(x_train.shape)
    
        #建立神经网络模型
    
        mlp=Sequential()
        mlp.add(Dense(units=20,input_dim=2,activation="sigmoid"))
        mlp.add(Dense(units=1,activation="sigmoid"))
        #输出模型结构
        mlp.summary()
    
        #模型的编译 compile the model
        # mlp.compile(optimizer='adam',loss='binary_crossentropy')
    
        #训练模型
        # mlp.fit(x_train,y_train,epochs=3000)
        save_path = r'data\mlp_model.h5'
        #保存好,已经训练好的模型
        # mlp.save(save_path)
    
        #加载模型
        mlp = load_model(save_path)
        #预测
        y_pred=mlp.predict(x_train)
    
    
    
        #上述是预测的概率,将其转换成0,1 ,如果是二分类问题用如下
        y_pred_class=(y_pred > 0.5).astype("int32")
        # 不是二分类问题用如下:
        # np.argmax(model.predict(x), axis=1)
    
    
    
        y_pred_class_form=pd.Series(i[0] for i in y_pred_class)
        print(y_pred_class_form)
    
    
    
        score=accuracy_score(y_train,y_pred_class)
        print(score)
    
        xx,yy=np.meshgrid(np.arange(0,1,0.01),np.arange(0,1,0.01))
        x_range=np.c_[xx.ravel(),yy.ravel()]
        y_range_predict=mlp.predict(x_range)
        y_range_predict_class=(y_range_predict > 0.5).astype("int32")
        y_range_predict_class_form=pd.Series(i[0] for i in y_range_predict_class)
    
    
    
        #画图
    
        fig7=plt.figure()
        plt.scatter(x_range[:,0][y_range_predict_class_form==1],x_range[:,1][y_range_predict_class_form==1])
        plt.scatter(x_range[:, 0][y_range_predict_class_form == 0], x_range[:, 1][y_range_predict_class_form == 0])
        passed = plt.scatter(data.loc[:, 'x1'][y == 1], data.loc[:, 'x2'][y == 1])
        faild = plt.scatter(data.loc[:, 'x1'][y == 0], data.loc[:, 'x2'][y == 0])
        plt.show()
    
    ```

    

27. 卷积神经网络

    ```perl
    参数非常多.
    怎样才能减少训练参数的数量
    提取图像中关键信息(轮廓),建立mlp模型
    
    图像卷积运算
    对于图像矩阵与滤波矩阵进行相乘再相加求和,转换为新的矩阵
    卷积: convolution
    卷积之后矩阵的大小计算:
    ((n-f)/s+1))*((n-f)/s+1))
    
    池化层:
    按照一个固定规则对图像矩形进行处理,变成更低维度的矩阵
    最大池化
    
    图像填充
    通过在图像各边添加像素,使其在进行卷积运算后维持原图大小
    
    经典的cnn模型:
    leNet-5
    AlexNet
    VGG
    ```

    

28.  ![image-20240122132618991](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122132618991.png)

     ![image-20240122133505614](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122133505614.png)

     ![image-20240122140709738](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122140709738.png)

     ![image-20240122141244627](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122141244627.png)

     ![image-20240122142837560](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122142837560.png)

     ![image-20240122143448044](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122143448044.png)

    ![image-20240122144158112](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122144158112.png)

     ![image-20240122144652524](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122144652524.png)

     ![image-20240122144946100](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122144946100.png)

     ![image-20240122151110189](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122151110189.png)

    v![image-20240122153052553](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122153052553.png)





![image-20240123174911475](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240123174911475.png)

30.  ![image-20240122153649604](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240122153649604.png)

2. conda 设置原

   ```perl
   pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple //pip 临时设置源
   conda config --remove-key channels //conda 恢复默认源
   conda config --add channels 'http://pypi.douban.com/simple/' //conda 设置阿里源
   pip install tensorflow -i https://mirrors.aliyun.com/pypi/simple --ignore-installed //安装TensorFlow
   pip install  scikit-learn -i https://pypi.tuna.tsinghua.edu.cn/simple  //安装sklearn
   
   ```

   

3. 二维和一维互相转换问题

   ```perl
   
   # Press the green button in the gutter to run the script.
   import tensorflow as tf
   from keras.preprocessing.image import ImageDataGenerator
   import pandas as pd
   import numpy as np
   if __name__ == '__main__':
       data = pd.read_csv('data/data.csv')
       x = data.drop(["y"], axis=1)
       y = data.loc[:, 'y']
   
       #pandas seriires 转换成 (n,1) 数据
       y_np=np.array(y)
   
       y_np_2=y_np.reshape(-1,1)
       print(y_np_2.shape)
       print(y_np_2)
   
       #将 上面的(n,1) 转成(n,)的一维数组
       y_np_1=y_np_2.flatten()
       print(y_np_1.shape)
       print(y_np_1)
   
       #将上面的二维(n,1) 转成pandas series 的数组
       y_pd_1=pd.Series(i[0] for i in y_np_2)
       print(y_pd_1.shape)
       print(y_pd_1)
   
   
   
       # print(tf.__version__)
       # train_datagen = ImageDataGenerator(rescale=1. / 255)
       # print(train_datagen)
   
   
   ```

   

33. cnn 猫狗分类

    ![image-20240123155123284](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240123155123284.png)

    ```python
    import tensorflow as tf
    from keras.preprocessing.image import ImageDataGenerator
    
    import pandas as pd
    import numpy as np
    from keras.models import Sequential
    from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten
    from keras.models import load_model
    from keras.preprocessing.image import load_img,img_to_array
    
    import os
    if __name__ == '__main__':
    
        # train_data=ImageDataGenerator(rescale=1./255,rotation_range=15,width_shift_range=0.2)
        # train_set=train_data.flow_from_directory('data/convolution/dataset/training_set',
        #                                          target_size=(50,50),
        #                                          batch_size=32,
        #                                          save_prefix='trans_',
        #                                          save_to_dir=save_path,
        #                                          class_mode='binary')
        # print(train_set)
    
    
        save_path = 'data/convolution/dataset/trans_pic'
        IMSIZE = (50, 50)  # width, height
        bs = 32
        # data_gen = ImageDataGenerator(rescale=1 / 255.0,
        #                               rotation_range=15,
        #                               width_shift_range=0.2,
        #                               height_shift_range=0.2,
        #                               horizontal_flip=True,
        #                               vertical_flip=True)
        data_gen = ImageDataGenerator(rescale=1./ 255.0)
        data = data_gen.flow_from_directory(directory='data/convolution/dataset/training_set',
                                            target_size=IMSIZE,
                                            batch_size=bs,
                                            save_prefix='trans_',
                                            save_to_dir=save_path,
                                            class_mode='binary'
    
                                            )
        print(data)
        print(data.class_indices)
    
        #建立cnn模型
        model=Sequential()
        #增加卷积层
        model.add(Conv2D(32,(3,3),input_shape=(50,50,3),activation='relu'))
    
        #增加池化层,不写strides 默认是2
        # model.add(MaxPooling2D(pool_size=(2,2),strides=(2)))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        #第二次卷积核池化
        model.add(Conv2D(32,(3,3),activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
    
        #flattening layer
        model.add(Flatten())
    
        #全链接层 FC layer
        #建立mlp模型
    
        model.add(Dense(units=128,activation='relu'))
        #最后的输出层
        model.add(Dense(units=1,activation='sigmoid'))
    
        #模型配置
        model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
        #查看模型结构
        model.summary()
    
        #训练模型
        # model.fit_generator(data,epochs=20)
        save_path = r'data\cnn.keras'
        # 保存好,已经训练好的模型
        # model.save(save_path)
        # 加载模型
        model = load_model(save_path)
        #训练数据的准确率
        # score=model.evaluate_generator(data)
        # print(score)
        #
        # #训练数据的准确性
        # test_data = data_gen.flow_from_directory(directory='data/convolution/dataset/test_set',
        #                                     target_size=IMSIZE,
        #                                     batch_size=bs,
        #
        #                                     class_mode='binary'
        #
        #                                     )
        # test_score = model.evaluate_generator(test_data)
        # print(test_score)
    
        #load single image
        pic_dog=load_img('test/5.jpg',target_size=(50,50))
        pic_dog=img_to_array(pic_dog)
    
        pic_dog=pic_dog/255
    
        pic_dog=pic_dog.reshape(1,50,50,3)
        re=model.predict(pic_dog)
        print(re)
    
    
    
    
    
    
        # for img, label in data:
        #     print(img.shape)
    
    
    ```

    cnn agg16

    ````perl
    import cnn_vgg16
    import pandas as pd
    import numpy as np
    from keras.preprocessing.image import img_to_array,load_img
    from keras.applications.vgg16 import VGG16
    from keras.applications.vgg16 import preprocess_input
    from sklearn.model_selection import train_test_split
    import os
    from keras.models import Sequential
    from keras.layers import Dense
    from sklearn.metrics import  accuracy_score
    def modelProcess(img_path,model):
        img = load_img(img_path, target_size=(224, 224))
        img = img_to_array(img)
        x = np.expand_dims(img,axis=0)
        x = preprocess_input(x)
        x_vgg = model.predict(x)
        x_vgg = x_vgg.reshape(1,25088)
        return x_vgg
    
    def getImageData(folder):
        dirs = os.listdir(folder)
        #测试代码
        # value=dirs[0]
        # dirs=[]
        # dirs.append(value)
    
        img_path = []
        for i in dirs:
            if os.path.splitext(i)[1] == ".jpg":
                img_path.append(i)
        img_path = [folder + "//" + i for i in img_path]
    
        # preprocess multiple images
        features1 = np.zeros([len(img_path), 25088])
        for i in range(len(img_path)):
            feature_i = modelProcess(img_path[i], model_vgg)
            print('preprocessed:', img_path[i])
            features1[i] = feature_i
    
        return features1
    
    if __name__ == '__main__':
    
    
        model_vgg=VGG16(weights='imagenet',include_top=False)
    
    
        catpath = "data/convolution/dataset/data_vgg/cats"
        dogpath = "data/convolution/dataset/data_vgg/dogs"
        catdata=getImageData(catpath)
        dogdata=getImageData(dogpath)
    
        print(catdata.shape,dogdata.shape)
        x=np.concatenate((catdata,dogdata),axis=0)
        y1 = np.zeros(300)
        y2 = np.ones(300)
        y=np.concatenate((y1, y2), axis=0)
        print(x)
        print(y)
    
        x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=50)
    
        #建立mlp模型
        mlp=Sequential()
        mlp.add(Dense(units=10,input_dim=25088,activation='relu'))
        mlp.add(Dense(units=1,activation='sigmoid'))
        mlp.summary()
    
        #配置模型
        mlp.compile(loss='binary_crossentropy',optimizer='adam')
    
        #训练模型
        mlp.fit(x_train,y_train,epochs=50)
    
        #评估模型
        y_train_predict=mlp.predict(x_train)
        y_pred_class = (y_train_predict > 0.5).astype("int32")
        score=accuracy_score(y_train,y_pred_class)
        print(score)
    
        #预测一张图片
        img=load_img('test/5.jpg',target_size=(224,224))
        img_data=img_to_array(img)
        xx=np.expand_dims(img_data,axis=0)
        xx=preprocess_input(xx)
        f1=model_vgg.predict(xx)
        f1=f1.reshape(1,7*7*512)
        result=mlp.predict(f1)
        print(result)
    
    ````

    

34. 循环神经网络

     ```perl
     序列模型
     输入或者输出中包含有序列数据的模型
     ```

      ![image-20240124155756035](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124155756035.png)

      ![image-20240124160436258](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124160436258.png)

      ![image-20240124161644093](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124161644093.png)

      ![image-20240124162536317](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124162536317.png)

      ![image-20240124162911265](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124162911265.png)

     ![image-20240124163107400](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124163107400.png)

      ![image-20240124163152921](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124163152921.png)

      ![image-20240124163546145](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124163546145.png)

      ![image-20240124164552184](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124164552184.png)

      ![image-20240124164652181](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124164652181.png)

      ![image-20240124165421286](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240124165421286.png)

    rnn 股票预测

    ```python
    import pandas as pd
    import numpy as np
    from matplotlib import pyplot as plt
    import matplotlib
    
    matplotlib.use("TkAgg")
    from sklearn.model_selection import train_test_split
    from keras.models import Sequential
    from keras.layers import Dense,Activation
    from sklearn.metrics import accuracy_score
    from keras.models import load_model
    from keras.datasets import mnist
    from keras.utils import to_categorical
    from keras.models import Sequential
    from keras.layers import Dense,SimpleRNN
    def extract_data(data,time_step):
        x=[]
        y=[]
        for i in range(len(data)-time_step):
            x.append([a for a in data[i:i+time_step]])
            y.append(data[i+time_step])
        x=np.array(x)
        #转换成rnn模型的数据格式
        # 1)样本数  2)timestep 3) 每个数据维度
        x=x.reshape(x.shape[0],x.shape[1],1)
        return x,y;
    
    if __name__ == '__main__':
        # #测试
        # # data_test=[0,1,2,3,4,5,6,7,8,9]
        # # x,y=extract_data(data_test,8)
        # # print(x)
        # # xx=np.array(x)
        # # print(xx)
        # # print(y)
        data=pd.read_csv('data/stock/zgpa_train.csv')
        price=data.loc[:,'close']
        time_step = 8
    
        #归一化处理
    
        price_norm=price/max(price)
        # print(price_norm)
    
        #可视化数据
        # fig=plt.figure()
        # plt.plot(price)
        # plt.title('close price')
        # plt.xlabel('time')
        # plt.ylabel('price')
    
        # plt.show()
    
        # define x and y
        time_step=8
        x,y=extract_data(price_norm,time_step)
        print(x.shape)
        print(x[0])
    
        #建立模型
        model=Sequential()
        model.add(SimpleRNN(units=5,input_shape=(time_step,1),activation='relu'))
        model.add(Dense(units=1,activation='linear'))
    
        #config model
        model.compile(loss='mean_squared_error',optimizer='adam')
        model.summary()
    
        #模型训练
        y=np.array(y)
        print(y)
        model.fit(x,y,batch_size=30,epochs=200)
    
        #预测训练数据
        y_predict=model.predict(x)
        y_predict=y_predict*max(price)
        y=y*max(price)
    
        fig = plt.figure()
    
        plt.plot(y)
        plt.plot(y_predict)
        plt.title('predict price')
        plt.xlabel('time')
        plt.ylabel('price')
    
        plt.show()
    
        #基于测试数据的预测
        data_test=pd.read_csv('data/stock/zgpa_test.csv')
        price_test=data_test.loc[:,'close']
        price_test_norm=price_test/max(price)
        x_test,y_test=extract_data(price_test_norm,time_step)
        y_test=np.array(y_test)
        print(x_test.shape,y_test.shape)
    
        #预测测试数据
        y_test_predict=model.predict(x_test)*max(price)
        y_test=y_test*max(price)
        fig5=plt.figure()
        plt.plot(y_test)
        plt.plot(y_test_predict)
        plt.xlabel('time')
        plt.ylabel('price')
        plt.legend()
        plt.show()
    
        #下载测试数据观察局部效果
    
        result_y_test=np.array(y_test).reshape(-1,1)
        result_y_test_predict=y_test_predict
        print(result_y_test.shape,result_y_test_predict.shape)
        result=np.concatenate((result_y_test,result_y_test_predict),axis=1)
        result=pd.DataFrame(result,columns=['real_price','predict_price'])
        result.to_csv('data/stock/stock.csv')
    
    ```

    

#### 深度学习

1. 单层感知机

    ![image-20240126164158837](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240126164158837.png)

    ![image-20240126174026082](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240126174026082.png)

2. ![image-20240126174644644](/Users/li/gitblog/blog1/blog/docs/study/images/image-20240126174644644.png)

   

### pytorch 基础

```perl
#安装pytorch
 conda install pytorch torchvision torchaudio cpuonly -c pytorch
 #梯度下降
 https://www.zhihu.com/question/305638940
```



##### 张量创建

1. pytorch 创建张量

    1)torch.tensor 根据指定数据创建张量

    2)torch.Tensor 根据形状创建张量

    3)torch.IntTesnsor torch.FloatTensor torch.DoubleTensor 创建张量

    ```perl
    在pytorch 张量以类形式封装起来,多维矩阵
    def test01():
        #1.1 创建标量
        data=torch.tensor(10)
        print(data)
        #使用numpy数组创建标量
        data1=np.random.randn(2,3)
        data_numpy=torch.tensor(data1)
        print(data_numpy)
        #使用list列表创建张量
        data=[[10.,20.,30.],[40.,50.,60.]]
        data=torch.tensor(data)
        print(data)
    #创建指定形状的张量
    def test02():
        #创建2行3列的张量
        #里面的数是随机的
        data=torch.Tensor(2,3)
        print(data)
        #创建指定值的张量
        data=torch.Tensor([1,2,3])
        print(data)
    
    #创建指定类型的张量
    def test03():
        data=torch.IntTensor(3,4)
        print(data)
        # torch.FloatTensor(2,4)# 创建的是int32
        # torch.LongTensor(2,3) #创建是long32
        # torch.ShortTensor(2,3) #创建是int16
    
        #注意创建指定类型的张量,但传递的数据不匹配,会发生类型转换
        data=torch.IntTensor([3.5,4.5])
        print(data)
    ```



2. 创建线性张量

   ```perl
   #创建线性张量
   def test01():
       #创建指定步长的张量
       #第一个参数:开始值
       #第二个参数:结束值
       #第三个参数:步长
       data=torch.arange(0,10,2)
       print(data)
       #在指定区间中指定元素个数
       #第一个参数开始值
       #第二个参数结束值
       #第三个参数:创建元素的个数
       data=torch.linspace(0,10,100)
       print(data)
   #创建随机张量
   def test02():
       #设置随机种子
       torch.manual_seed(123)
       data=torch.randn(2,3)
       print(data)
       seed=torch.random.initial_seed()
       print("随机种子",seed)
   
   
   
   ```

   

3. 创建全01张量

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   #创建全为0的张量
   def test01():
       #指定形状全为0的张量
       data=torch.zeros(2,3)
       print(data)
       #根据其他张量的形状创建全0的张量
       data=torch.zeros_like(data)
       print(data)
   
   #创建全为1的张量
   def test02():
       # 指定形状全为1的张量
       data = torch.ones(2, 3)
       print(data)
       # 根据其他张量的形状创建全1的张量
       data = torch.ones_like(data)
       print(data)
   #创建指定值的张量
   def test03():
       data=torch.full([2,3],10)
       print(data)
       #创建形状和data一样值为100的张量
       data=torch.full_like(data,100)
       print(data)
   ```

   

4. 张量类型转换

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   #使用type函数进行转换
   def test01():
       data=torch.full([2,3],10)
       print(data)
       print(data.dtype)
       data=data.type(torch.DoubleTensor)
       print(data)
       print(data.dtype)
   
   
   
   
   
   #使用具体类型函数进行转换
   def test02():
       data = torch.full([2, 3], 10)
       print(data)
       data=data.double()
       print(data.dtype) #torch.float64
       data=data.float()
       print(data.dtype) #torch.float32
   ```

##### 张量的计算

1. 张量的计算

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   #不修改原数据的计算
   def test01():
       #第一个参数:开始值
       #第二个参数:结束值
       #第三个参数: 形状
       data=torch.randint(0,10,[2,3])
       print(data)
       #计算完成后会返回一个新的张量
       data=data.add(10)
       print(data)
       # data.sub() #减法
       # data.mul() #乘法
       # data.div()#除法
       # data.neg() #取反
   
   
   #修改元数据的计算
   def test02():
       data = torch.randint(0, 10, [2, 3])
       print(data)
       data.add_(10)
       print(data)
   ```

   

2. 实现哈达玛积运算

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
    #使用mul函数计算哈达玛积
   def test01():
       data1=torch.tensor([[1,2],[3,4]])
       data2=torch.tensor([[5,2],[6,7]])
       data=data1.mul(data2)
       print(data)
   
   
   
   
   #使用* 号实现
   def test02():
       data1 = torch.tensor([[1, 2], [3, 4]])
       data2 = torch.tensor([[5, 2], [6, 7]])
       
       data=data2*data1
       print(data)
   
   ```

   

3. 点积计算

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
    #使用@符号进行点积运算
   def test01():
       data1=torch.tensor([[1,2],[3,4],[5,6]])
       data2=torch.tensor([[5,2],[6,7]])
       data=data1@data2
       print(data)
   
   #使用mm函数,要求都是二维的
   def test02():
       data1 = torch.tensor([[1, 2], [3, 4], [5, 6]])
       data2 = torch.tensor([[5, 2], [6, 7]])
       data=torch.mm(data1,data2)
       print(data)
   
   #使用bmm函数,要求都是三维的
   def test03():
       #第一参数:表示批次
       #第二个参数:多少行
       #第二个参数:多少列
       data1=torch.randn(3,4,5)
       data2=torch.randn((3,5,8))
       data=torch.bmm(data1,data2)
       print(data.shape)
   #使用matmul,既可以使用二维,也可以使用3纬
   def test04():
       #三维
       data1=torch.randn(3,6,5)
       data2=torch.randn(3,5,2)
       data=torch.matmul(data1,data2)
       print(data.shape)
       #二纬
       data3=torch.randn(3,5)
       data4=torch.randn(5,6)
       data=torch.matmul(data3,data4)
       print(data.shape)
       # 三维对二维
       data5 = torch.randn(3, 6, 5)
       data6=torch.randn(5,8)
       data=torch.matmul(data5,data6)
       print(data.shape)
   ```

   

4. 指定运算设备

   ```perl
   def test01():
       data=torch.tensor([1,2,3,4])
       print("存储设备",data.device)
       #将张量移动到cpu上
       data=data.cuda()
       print("存储设备", data.device)
       #将张量从gpu 移动到cpu
       data=data.cpu()
       print("存储设备", data.device)
   
   #直接将张量创建在指定设备
   def test02():
       data=torch.tensor([1, 2, 3, 4],device='cuda:0')
       print("存储设备", data.device)
   
   #to 方法移动张量到指定设备
   def test03():
       data=torch.tensor([1, 2, 3, 4])
       data=data.to('cuda:0')
       print("存储设备", data.device)
   
   #存储在不同设备的张量不能够直接运算
   def test04():
       data1 = torch.tensor([1, 2, 3, 4])
       data2=torch.tensor([1, 2, 3, 4],device='cuda:0')
       data=data1+data2 #张量在不同的设备上不能运算
       print(data)
   ```

##### 张量的类型转换

1. 张量转换为numpy

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   #张量转换为numpy数组
   def test01():
       data=torch.tensor([1,2,3,4])
       print(type(data))
       data=data.numpy()
       print(type(data))
       print(data)
   
   #张量和numpy共享内存
   def test02():
       data = torch.tensor([1, 2, 3, 4])
   
       data1 = data.numpy()
       #修改张量元素的值,看看numpy数组是否发生变化:会发生变化
       data.add_(10)
       print(data1)
       #修改numpy数组,张量是否有变化:会发生变化
       data1[0]=100
       print(data)
   
   #张量和numpy不共享内存,用copy函数
   def test03():
       data = torch.tensor([1, 2, 3, 4])
   
       data1 = data.numpy().copy()
       print(data1)
   ```

   

2. numpy转换为张量

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   #from_numpy的用法
   #将numpy转换为pytorch 的张量
   def test01():
       data=np.array([1,2,3,4])
       #from_numpy 是共享内存的,所以里面要调用numpy的copy函数
       data1=torch.from_numpy(data.copy())
       print(type(data1))
       data[0]=100
       print(data)
       print(data1)
   
   #使用tensor
   def test02():
       
       data = np.array([1, 2, 3, 4])
       #torch.tensor不共享内存
       data1=torch.tensor(data)
       print(data1)
   ```

   

3. 从张量中,提取数字

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   #从标量中提取值
   def test01():
       data1=torch.tensor(10)
       data2=torch.tensor([10])
       data3=torch.tensor([[10]])
       print(data1.shape)
       print(data2.shape)
       print(data3.shape)
       print(data2.item())
       print(data3.item())
       #注意张量中只有一个元素,如果有多个元素的话
       #使用item函数可能就会报错
   ```

##### 张量的拼接操作

1. torch.cat函数的使用

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   
   def test01():
       data1=torch.randint(0,10,[3,4,5])
       data2=torch.randint(0, 10, [3, 4, 5])
       print(data1.shape)
       print(data2.shape)
       #安装0维度进行拼接 torch.Size([6, 4, 5])
       data=torch.cat([data1,data2],dim=0)
       print(data.shape)
   
       #安装1维度进行拼接 torch.Size([3, 8, 5])
       data = torch.cat([data1, data2], dim=1)
       print(data.shape)
   
       #安装第2个维度拼接 torch.Size([3, 4, 10])
       data = torch.cat([data1, data2], dim=2)
       print(data.shape)
   ```

   

2. torch.stack函数的使用

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   
   def test01():
           torch.manual_seed(0)
           data1 = torch.randint(0, 10, [2, 3])
           data2 = torch.randint(0, 10, [2, 3])
   
   
           data3=torch.stack([data1, data2], dim=0)
           print(data1)
           print(data2)
           print("-"*30)
           print(data3)
           print(data3.shape)
           data4 = torch.stack([data1, data2], dim=1)
   
           print("-" * 30)
           print(data4)
           print(data4.shape)
   
           data5 = torch.stack([data1, data2], dim=2)
   
           print("-" * 30)
           print(data5)
           print(data5.shape)
   ```

张量的行列索引

```perl
import torch
import torch.nn.functional as F
import numpy as np

#简单的行列索引
def test01():
    data=torch.randint(0,10,[4,5])
    print(data)
    print('-'*30)
    #获得指定某行的元素
    print(data[2])
    #获得指定某个列的元素
    print('-'*30)
    #逗号前面表示行,逗号后面表示列
    #tensor([0, 0, 1, 3])
    print(data[:,0])
    #冒号表示所有行,或者所有列
    print('-' * 30)
    #1:4 1:表示从第一行开始,4 表示从4行结束
    #tensor([0, 1, 3])
    print(data[1:4,0])
    #获得指定位置的某个元素
    print(data[1,2])
    #获得前三行,前两列的数据
    print(data[:3,:2])

    #用列表获取元素tensor([5, 3])
    print(data[[1,2],[1,2]])
```



```perl
import torch
import torch.nn.functional as F
import numpy as np

#张量的布尔索引
def test01():
    torch.manual_seed(0)
    data=torch.randint(0,10,[4,5])
    print(data)
    #取得所有元素大于3的元素
    #[4, 9, 9, 7, 7, 6, 6, 9, 8, 6, 6, 8, 4]
    print(data[data>3])

    #返回第2列元素大于6的行
    print(data[:,1]>6)
    print(data[data[:,1]>6])

    #希望返回第2行元素大于3的所有列
    print(data[:,data[1]>3])

#多维索引
def test02():
    torch.manual_seed(0)
    data = torch.randint(0, 10, [3, 4, 5])
    print(data)
    print('-' * 30)
    #按照0个维度选择0元素
    print(data[0,:,:])

    #按照1个维度选择元素,取每个的第一行
    # tensor([[4, 9, 3, 0, 3],
    #         [6, 9, 1, 4, 4],
    #         [8, 3, 6, 9, 1]])
    print('-' * 30)
    print(data[:,0,:])

    print('-' * 30)
    #选择2个维度的元素,取每个第一列
    print(data[:,:,0])
```

张量的形状操作

1. reshape函数的用法

   ```perl
   1.shape size() 查看张量的形状
   2.在保证张量数据不变的前提下改变数据维度,将其转换成指定的形状
   ```

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   #张量的形状
   def test01():
           torch.manual_seed(0)
           data = torch.randint(0, 10, [4, 5])
           print(data)
           print(data.shape)
           # print(data.shape[0])
           # print(data.shape[1])
           # print(data.size())
           # print(data.size(0))
           # print(data.size(1))
           #修改张量的形状
           new_data=data.reshape(2,10)
           print(new_data)
           #转换形状的个数等于原来张量元素的个数
           # new_data1=data.reshape(1, 10)
           # print(new_data1)
   #torch.transpose
   #可以一次交换2个维度
   
   def test02():
           torch.manual_seed(0)
           data = torch.randint(0, 10, [3, 4, 5])
           print(data)
           # new_data = data.reshape(4, 3, 5)
           # print(new_data)
           #直接交换两个维度的值
           new_data=torch.transpose(data,0,1)
           print(new_data.shape)
           #缺点一次只能交换两个维度
   
   #permute 函数
   def test03():
           torch.manual_seed(0)
           data = torch.randint(0, 10, [3, 4, 5])
           new_data=torch.permute(data,[2,1,0])
           print(new_data.shape)
   
   ```

   

2. unsqeeze 和squeeze函数的使用

   ```perl
   import torch
   import torch.nn.functional as F
   import numpy as np
   
   #squeeze函数的使用
   #squeeze 函数的作用:删除shape 为1 的维度
   def test01():
           data = torch.randint(0, 10, [1, 3, 1, 5])
           print(data.shape)
           #维度压缩,默认去掉所有为1的维度
           new_data=data.squeeze()
           print(new_data.shape)
           #删除指定某个1的维度
           new_data=data.squeeze(2)
           print(new_data.shape)
   
   #unsqueeze 函数,在每个维度增加1,以增加数据维度
   def test02():
           data = torch.randint(0, 10, [3, 5])
           print(data.shape)
           # 可以在指定位置增加维度
           # -1 代表最后一个维度
           #torch.Size([1, 3, 5])
           new_data = data.unsqueeze(0)
           # new_data = data.unsqueeze(-1)
           print(new_data.shape)
   ```

张量的运算

```perl
import torch
import torch.nn.functional as F
import numpy as np

#squeeze函数的使用
#squeeze 函数的作用:删除shape 为1 的维度
def test01():
    torch.manual_seed(0)
    # data = torch.randint(0, 10, [2, 3], dtype=torch.float64)
    data = torch.randint(0, 10, [2, 3]).double()
    print(data)
    #均值运算
    print(data.mean())
    #指定维度的均值
    print(data.mean(dim=0)) #列方式均值
    # 指定维度的均值
    print(data.mean(dim=1)) #行方式均值

    #求和
    print(data.sum())
    print(data.sum(dim=0))
    print(data.sum(dim=1))
```

自动微分模块



1. r
2. r
3. 

















 









